{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.0.0\n",
      "numpy: 1.12.1\n",
      "matplotlib: 2.1.0\n",
      "pandas: 0.21.1\n",
      "sklearn: 0.19.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__)) # numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "import datetime\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) # pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "#scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import xlrd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import zipcode\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (38,39,43,50,203,204,206,207,212,213,215,216,218,219,224,225,227,228,230,231,233,234,241,242,244,245,247,248,251,252,348,349,351,354,356,358,382,384,385,386,387,390,391) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('SuperZooData/Registration_Data/SuperZoo_2016_Registrants_No_Minors.csv', header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (39,40,43,62,63,84,120,121,145,146,148,149,160,161,191,192,224,225,227,228,236,237,269,270,272,273,275,276,284,285,344,346,350,352,353,360,361,373,385,386,387) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('SuperZooData/Registration_Data/SuperZoo_2017_Registrants_No_Minors.csv', header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotting = data['AddDate Date'].value_counts().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.index.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(150, 150))\n",
    "plt.plot(plotting.index.sort_values(ascending=True), plotting)\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('date', ascending=True)\n",
    "plt.plot(df['date'], df['count'])\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dups_with_dif_index_check(data):\n",
    "    dupes = {}                        # checks to see if duplicated columns with different index values\n",
    "    for col_a in data.columns:\n",
    "        dupes[col_a] = []\n",
    "\n",
    "        for col_b in data.columns:\n",
    "            if col_b in dupes.keys():\n",
    "                continue\n",
    "            if (data.loc[:,col_a] == data.loc[:,col_b]).sum() == len(data.loc[:,col_a]):\n",
    "                dupes[col_a].append(col_b)    \n",
    "   \n",
    "    bad_cols = []   \n",
    "    for col, dup_cols in dupes.iteritems():\n",
    "        bad_cols += dup_cols\n",
    "    bad_cols = set(bad_cols)\n",
    "\n",
    "    data = data.loc[:,~data.columns.isin(bad_cols)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_dups_na(data):\n",
    "    data = data.loc[:,~data.columns.duplicated()] \n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    data = data.dropna(axis=0, how='all')\n",
    "    data = dups_with_dif_index_check(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def def_time_modify(data, date_checker):\n",
    "    data[\"AddDate Date\"] = pd.to_datetime(data[\"AddDate Date\"])\n",
    "    data['ModifyDate Date'] = pd.to_datetime(data['ModifyDate Date'])\n",
    "    for a in range(0,len(data.iloc[:,data.columns.get_loc('ModifyDate Date')])):\n",
    "        if data.iloc[a,data.columns.get_loc('ModifyDate Date')] > date_checker:\n",
    "            data.iloc[a,data.columns.get_loc('ModifyDate Date')] = data.iloc[a,data.columns.get_loc(\"AddDate Date\")]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time_update(data, date_checker):\n",
    "    data = data[data[\"AddDate Date\"] <= date_checker]\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_drop_other_text(data):\n",
    "    col = []\n",
    "    for a in data.columns:\n",
    "        if \"_text\" in a or \"_other\" in a:\n",
    "            col.append(a)\n",
    "    data=data.drop(labels = col, axis =1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rid_of_nonnumerical_answer(data):\n",
    "    col = [] # THIS NEEDS TO BE CHANGED FOR NEW DATA SET\n",
    "    checker = 1\n",
    "    for a in data.columns:\n",
    "        if '_codes' in a and checker ==1:\n",
    "            checker = 0\n",
    "        if '_codes' not in a and checker == 0:\n",
    "            col.append(a)\n",
    "    data = data.drop(col, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answers_dummies(data):\n",
    "    column =[]\n",
    "    for a in data.columns:\n",
    "        if \"_codes\" in a:\n",
    "            column.append(a)  \n",
    "    for a in column:\n",
    "        new_data = data[a].str.get_dummies(sep=',')\n",
    "        data = pd.concat([data, new_data], axis=1)\n",
    "        data = data.drop([a], axis = 1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_change_string_drop_dups(data):\n",
    "    for a in data.columns:\n",
    "        if data[a].dtype== np.dtype('O'):\n",
    "            data[a] = data[a].astype('S32')\n",
    "    cols = list(data)    # THIS DROPS ALL COLUMNS THAT HAVE THE SAME VALUE\n",
    "    nunique = data.apply(pd.Series.nunique)\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purchase_dummies(data):\n",
    "    new_data = data['PurchaseItems'].str.get_dummies(sep=',')\n",
    "    data = pd.concat([data, new_data], axis=1)\n",
    "    data = data.drop(['PurchaseItems'], axis = 1)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def state_dummies(data):\n",
    "    s = data.State.value_counts()\n",
    "    s = data.State.value_counts()[s > (8)].index #8\n",
    "    holder = pd.get_dummies(data.State)\n",
    "    holder_smaller = holder[s]\n",
    "    data = pd.concat([data, holder_smaller], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_zip(data):\n",
    "    data.loc[data.loc[:,'ZipPostal'].str.contains('-', na = False),'ZipPostal'] = data.loc[data.loc[:,'ZipPostal'].str.contains('-', na = False),'ZipPostal'].str.split('-',n = 1, expand = True)[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_distance(data):\n",
    "    data = check_zip(data)\n",
    "    geolocator = Nominatim()\n",
    "    vegas = zipcode.isequal('89178')\n",
    "    veg = (vegas.lat, vegas.lon)\n",
    "    col= []\n",
    "    for idx, val in enumerate (data.ZipPostal):\n",
    "        try:\n",
    "            city = zipcode.isequal(val)\n",
    "            cit = (city.lat, city.lon)\n",
    "            col.append(vincenty(veg, cit).miles)\n",
    "        except:\n",
    "            try:\n",
    "                city = geolocator.geocode(data.loc[idx,'Country']+\" \"+val)\n",
    "                cit = (city.latitude, city.longitude)\n",
    "                col.append(vincenty(veg, cit).miles)\n",
    "            except:\n",
    "                col.append('nan')\n",
    "    data.insert(0, 'Distance', col, allow_duplicates=False)\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_name(data):\n",
    "    data.Company = data.Company.str.lower()\n",
    "    data.loc[:,'Company']=~data.loc[:,'Company'].str.contains('bone|wash|claw|pet|dog|woof|wag|tail|bark|groom|paw|animal|chow|poodle|fur|hound|canine|pup|pooch|feed|fish|aqua|reptile|suppl|k9|bird|feather|seed|mutt|swine',na = False, regex = True) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_split_username(data):\n",
    "    data.loc[:,'Email_Username'] = data.Email.str.split('@',n = 1, expand = True)[0]\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_contains_username(data):\n",
    "    data.loc[:,'Email_Username']=~data.loc[:,'Email_Username'].str.contains('bone|wash|claw|pet|dog|woof|wag|tail|bark|groom|paw|animal|chow|poodle|fur|hound|canine|pup|pooch|feed|fish|aqua|reptile|suppl|k9|bird|feather|seed|mutt|swine',na =False, regex = True) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_split_host(data):\n",
    "    data.loc[:,'Email_Host'] = data.Email.str.split('@',n = 1, expand = True)[1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_cleanup(data):\n",
    "    data.Email = data.Email.str.lower()\n",
    "    data.loc[:,'Email'][~data.loc[:,'Email'].str.contains('@')] = 'a@a'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_contains_hostname(data):\n",
    "    data.loc[data.loc[:,'Email_Host'].str.contains('bone|wash|claw|pet|dog|woof|wag|tail|bark|groom|paw|animal|chow|poodle|fur|hound|canine|pup|pooch|feed|fish|aqua|reptile|suppl|k9|bird|feather|seed|mutt|swine', na = False,regex = True), 'Email_Host'] = 'PET'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_change(data):\n",
    "    data = email_cleanup(data)\n",
    "    data = email_split_username(data)\n",
    "    data = email_split_host(data)\n",
    "    data = email_contains_username(data)\n",
    "    data = email_contains_hostname(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_dummies(data):\n",
    "    data = email_change(data)\n",
    "    s = data.Email_Host.value_counts()\n",
    "    s = data.Email_Host.value_counts()[s > (48)].index  #48\n",
    "    holder = pd.get_dummies(data.Email_Host)\n",
    "    holder_smaller = holder[s]\n",
    "    data = pd.concat([data, holder_smaller], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_drops(data):\n",
    "    data = data.drop(['WebUrl',\"CheckInDate Date\",\"Aux1\", \"Aux5\",\"FirstPrintDate Time\",\"FirstPrintLocId\", 'FirstPrintStationId','CheckInDate Time',\"ModifyDate Time\", \"IndexDate\"], axis = 1)\n",
    "    data = data.drop(['RegTypeDesc','SourceApp','CountryName','StreamSteps','StreamName', 'RegType','StreamStep',\"AddUserId\",\"ModifyUserId\",\"AddDate Time\"], axis = 1)\n",
    "    data = data.drop([\"Pwd\", \"UserName\", \"AccountKeyPublic\",\"AccountKeyPrivate\", \"Notes\",'Id', 'AccountId', 'ClientIp', 'StreamId','State', 'StreamStatus'], axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_dummies(data):\n",
    "    data = pd.get_dummies(data,columns = ['Aux6', 'ApprovalUserId', 'LangId', 'MemberStatus', 'TermsAccepted'], dummy_na = True)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_dummies_cleanup(data):\n",
    "    d = {'3001': ['3001', '3001.1']}   \n",
    "    data = data.rename(columns=lambda c: d[c].pop(0) if c in d.keys() else c)\n",
    "    d = {'2001': ['2001', '2001.1']}\n",
    "    data = data.rename(columns=lambda c: d[c].pop(0) if c in d.keys() else c)\n",
    "    # renames duplicate column names\n",
    "    d = {'TermsAccepted_nan': ['TermsAccepted_nan', 'TermsAccepted_nan.1']}\n",
    "    data = data.rename(columns=lambda c: d[c].pop(0) if c in d.keys() else c)\n",
    "    d = {'MemberStatus_nan': ['MemberStatus_nan', 'MemberStatus_nan.1']}\n",
    "    data = data.rename(columns=lambda c: d[c].pop(0) if c in d.keys() else c)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data):\n",
    "    date_checker = datetime.datetime(2016,7,23) #train_X 2016,6,3 2016,7,23    test_X 2017,5,24  2017,7,13   \n",
    "    data = zip_distance(data)\n",
    "    data = data.apply(pd.to_numeric, errors='ignore')\n",
    "    data = clear_dups_na(data)\n",
    "    data = def_time_modify(data, date_checker)\n",
    "    data = date_time_update(data, date_checker)                      #DONT FORGET TO CHANGE THIS UP HERE! THE DATES!!!\n",
    "    data = data_drop_other_text(data)\n",
    "    data = get_rid_of_nonnumerical_answer(data)\n",
    "    data = answers_dummies(data)\n",
    "    data = data_change_string_drop_dups(data)\n",
    "    data = purchase_dummies(data)\n",
    "    data = state_dummies(data)\n",
    "    data = email_dummies(data)\n",
    "    data = column_drops(data)\n",
    "    data = data_dummies(data)\n",
    "    data = data_dummies_cleanup(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = processing_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan              669\n",
       "8311.53649198    403\n",
       "238.142872527    121\n",
       "8929.99114339    102\n",
       "24.1011894369     85\n",
       "12.6881755978     70\n",
       "13.5118945605     68\n",
       "619.316904052     66\n",
       "22.6114343371     66\n",
       "11.0882285693     64\n",
       "11.2060057264     64\n",
       "16.8850855957     62\n",
       "2250.19822755     57\n",
       "629.658024429     55\n",
       "22.8625825643     54\n",
       "29.3606737306     53\n",
       "240.474544128     51\n",
       "9539.50296971     48\n",
       "630.537340659     46\n",
       "223.265620559     45\n",
       "16.3510640211     45\n",
       "0.0               44\n",
       "24.0282595168     44\n",
       "196.354932766     43\n",
       "616.018464698     42\n",
       "217.933598322     41\n",
       "19.9885974154     38\n",
       "87.1691187086     38\n",
       "22.4046895685     38\n",
       "20.3752471783     37\n",
       "                ... \n",
       "1518.81366811      1\n",
       "3225.80141754      1\n",
       "125.500131602      1\n",
       "2006.16510934      1\n",
       "1684.11413345      1\n",
       "2005.39380805      1\n",
       "218.298666094      1\n",
       "268.77899304       1\n",
       "454.600557328      1\n",
       "19.5071858454      1\n",
       "1068.37669541      1\n",
       "876.175377633      1\n",
       "341.292033843      1\n",
       "1065.54946494      1\n",
       "2395.85369586      1\n",
       "363.60732741       1\n",
       "1714.49902905      1\n",
       "250.53249888       1\n",
       "1388.14495312      1\n",
       "290.424362772      1\n",
       "1184.54084183      1\n",
       "1944.64302968      1\n",
       "328.096346832      1\n",
       "2250.05162019      1\n",
       "1985.45099833      1\n",
       "2172.67128184      1\n",
       "1061.32432108      1\n",
       "391.332224225      1\n",
       "256.899666923      1\n",
       "357.091913587      1\n",
       "Name: Distance, Length: 1825, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.Distance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = processing_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"Data_Zoo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_pickle(\"Data_Zoo_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"Data_Zoo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(\"Data_Zoo_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = company_name(data)\n",
    "test_data = company_name(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12875, 357)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10242, 349)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(data.T.drop_duplicates(subset=data.index)).T  # to big of a dataset to use this to get rid of duplicate columns with different names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for a in range(0,len(data.columns)):                                          # look at values of columns\n",
    "#    if len(data.iloc[:,1])-data.iloc[:,a].isnull().sum() == 0:\n",
    "#         print data.columns[a], len(data.iloc[:,1])-data.iloc[:,a].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_to_event(data, test_data, date, test_date):\n",
    "    data[\"Days_to_Event\"] = (date - data['AddDate Date']).dt.days\n",
    "    test_data[\"Days_to_Event\"] = (test_date - test_data['AddDate Date']).dt.days\n",
    "    return data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_to_event_modify(data, test_data, date, test_date):\n",
    "    data[\"Days_to_Event_Modify\"] = (date - data['ModifyDate Date']).dt.days\n",
    "    test_data[\"Days_to_Event_Modify\"] = (test_date - test_data['ModifyDate Date']).dt.days\n",
    "    return data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_for_train(train_data):\n",
    "    y =[]\n",
    "    for a in train_data['FirstPrintDate Date']:\n",
    "        if a == 'nan':\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_for_test(test_data):\n",
    "    y =[]\n",
    "    for a in test_data['FirstPrintDate Date']:\n",
    "        if a == 'nan':\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_column_sync(data, test_data):\n",
    "    col=[]\n",
    "    for a in data.columns:\n",
    "        for b in test_data.columns:\n",
    "            if a == b:\n",
    "                col.append(b)    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_impute_Distance(data):\n",
    "    imp=Imputer(missing_values=\"NaN\", strategy=\"mean\" )\n",
    "    data[\"Distance\"]=imp.fit_transform(data[[\"Distance\"]]).ravel()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_impute(X):\n",
    "    data_X_hold = X.columns\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    imp.fit(X)\n",
    "    data_T=imp.transform(X)\n",
    "    X = pd.DataFrame(data_T, columns = data_X_hold)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_processing(data, test_data):\n",
    "    date = datetime.datetime(2016,7,23)\n",
    "    test_date = datetime.datetime(2017,7,13)\n",
    "    train_Y = y_for_train(data)\n",
    "    test_Y = y_for_test(test_data)\n",
    "    data = data_impute_Distance(data)\n",
    "    test_data = data_impute_Distance(test_data)\n",
    "    data, test_data = day_to_event(data, test_data, date, test_date)\n",
    "    data, test_data = day_to_event_modify(data, test_data, date, test_date)\n",
    "    test_data = test_data.apply(pd.to_numeric, errors='ignore')\n",
    "    train_X = data.select_dtypes(include = ['int64', 'float64', 'uint8', 'bool']).iloc[:, 0:]\n",
    "    test_X = test_data.select_dtypes(include = ['int64', 'float64', 'uint8', 'bool']).iloc[:, 0:]\n",
    "    col = train_test_column_sync(train_X, test_X)\n",
    "    train_X = data[col]\n",
    "    test_X = test_data[col]\n",
    "    train_X = data_impute(train_X)\n",
    "    test_X = data_impute(test_X)\n",
    "    return (train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_processing(data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc[:,'sum_response'] = train_X.loc[:,'0201':'508'].sum(axis=1)\n",
    "test_X.loc[:,'sum_response'] = test_X.loc[:,'0201':'508'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ml as pdml\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = pd.DataFrame(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = pd.concat([train_X, train_Y], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = pdml.ModelFrame(data_normalized, target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = data_normalized.imbalance.over_sampling.SMOTE()\n",
    "sampled = data_normalized.fit_sample(sampler)\n",
    "sampled=pd.DataFrame(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = sampled.sample(frac=1)\n",
    "train_Y = sampled[0]\n",
    "train_X = sampled.drop([0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 1035\n",
      "Company 8895\n",
      "Phone1CountryPrefix 15497\n",
      "Phone2Number 48\n",
      "FaxCountryPrefix 7849\n",
      "AmountBilled 14621\n",
      "AmountPaid 14984\n",
      "AmountDue 15987\n",
      "0201 15472\n",
      "0202 15632\n",
      "0203 15671\n",
      "0204 15143\n",
      "0205 15055\n",
      "0206 13045\n",
      "0207 12473\n",
      "0208 11498\n",
      "0209 10506\n",
      "0210 15492\n",
      "0211 15362\n",
      "0212 14181\n",
      "0213 13964\n",
      "0214 15478\n",
      "0215 13223\n",
      "0216 13298\n",
      "0217 15661\n",
      "0218 15567\n",
      "0219 15144\n",
      "0220 15013\n",
      "0221 15393\n",
      "0222 15285\n",
      "0223 15380\n",
      "0224 15766\n",
      "0225 14998\n",
      "0226 15687\n",
      "0227 15419\n",
      "0401 16340\n",
      "0402 16366\n",
      "0501 16374\n",
      "0502 16365\n",
      "0601 16382\n",
      "0602 16365\n",
      "0701 16344\n",
      "0702 16382\n",
      "1101 16383\n",
      "1103 16374\n",
      "1201 16197\n",
      "1301 16194\n",
      "1401 16194\n",
      "1501 16194\n",
      "1601 16282\n",
      "1801 16301\n",
      "1901 16359\n",
      "1902 16285\n",
      "2001 16336\n",
      "2101 16367\n",
      "2201 16352\n",
      "2202 16367\n",
      "2203 16320\n",
      "2301 16377\n",
      "2302 16386\n",
      "2304 16295\n",
      "2305 16385\n",
      "2307 16387\n",
      "2309 16379\n",
      "2310 16387\n",
      "2401 16373\n",
      "2402 16382\n",
      "2403 16309\n",
      "3001 16385\n",
      "3101 16383\n",
      "3102 16384\n",
      "3103 16349\n",
      "3201 16370\n",
      "3301 16361\n",
      "3401 16367\n",
      "3501 16376\n",
      "3601 16336\n",
      "3801 16371\n",
      "3802 16377\n",
      "3901 16386\n",
      "3902 16371\n",
      "4001 16377\n",
      "4101 16358\n",
      "4301 15849\n",
      "4302 15578\n",
      "4303 15908\n",
      "4304 16299\n",
      "4305 16268\n",
      "4306 16237\n",
      "4310 16381\n",
      "4311 16238\n",
      "4312 15913\n",
      "4313 15936\n",
      "4314 16157\n",
      "4315 16300\n",
      "4316 16192\n",
      "4317 16360\n",
      "4318 16265\n",
      "4319 16352\n",
      "4321 16357\n",
      "4322 15982\n",
      "4323 16352\n",
      "4324 15364\n",
      "4325 16353\n",
      "4326 16304\n",
      "4327 16366\n",
      "4329 15979\n",
      "4330 15680\n",
      "4331 16343\n",
      "4701 16350\n",
      "4801 16336\n",
      "4901 16367\n",
      "5001 16322\n",
      "5002 16303\n",
      "1001 16303\n",
      "1002 16056\n",
      "1003 16219\n",
      "1004 16238\n",
      "1005 16360\n",
      "1006 16276\n",
      "1007 16315\n",
      "1008 16295\n",
      "1009 16243\n",
      "1010 16277\n",
      "1011 16318\n",
      "1012 16284\n",
      "1013 16252\n",
      "1014 16347\n",
      "1015 16244\n",
      "1016 16331\n",
      "1017 16279\n",
      "1018 16281\n",
      "1019 16238\n",
      "1020 16283\n",
      "1021 16272\n",
      "1022 16285\n",
      "1023 16289\n",
      "1024 16268\n",
      "1025 16343\n",
      "2001.1 16351\n",
      "2002 16327\n",
      "2003 16366\n",
      "2004 16374\n",
      "2005 16345\n",
      "2006 16349\n",
      "2007 16370\n",
      "2008 16327\n",
      "2009 16313\n",
      "2010 16376\n",
      "2011 16285\n",
      "2012 16364\n",
      "2013 16363\n",
      "2014 16337\n",
      "2015 16322\n",
      "2016 16372\n",
      "2017 16320\n",
      "2018 16354\n",
      "2019 16313\n",
      "2020 16384\n",
      "2021 16333\n",
      "2022 16346\n",
      "2023 16382\n",
      "2024 16270\n",
      "2025 16364\n",
      "2026 16380\n",
      "2027 16321\n",
      "2028 16366\n",
      "2029 16359\n",
      "2030 16362\n",
      "2031 16343\n",
      "2032 16319\n",
      "2033 16329\n",
      "2034 16388\n",
      "2035 16341\n",
      "2036 16362\n",
      "2037 16361\n",
      "2038 16363\n",
      "2039 16340\n",
      "2040 16360\n",
      "2041 16358\n",
      "2042 16345\n",
      "3002 16382\n",
      "3003 16379\n",
      "3004 16379\n",
      "3005 16386\n",
      "3006 16381\n",
      "3007 16341\n",
      "3008 16386\n",
      "3009 16385\n",
      "3010 16381\n",
      "3011 16381\n",
      "3012 16385\n",
      "3013 16377\n",
      "3014 16385\n",
      "3015 16387\n",
      "3016 16384\n",
      "3017 16359\n",
      "3018 16385\n",
      "3019 16377\n",
      "3020 16381\n",
      "3021 16379\n",
      "3022 16352\n",
      "403 16098\n",
      "404 16339\n",
      "405 16351\n",
      "406 16351\n",
      "407 16352\n",
      "408 16256\n",
      "409 16383\n",
      "503 16217\n",
      "504 16384\n",
      "505 16380\n",
      "506 16362\n",
      "507 16381\n",
      "508 16313\n",
      "ATL 8202\n",
      "ATT 8202\n",
      "CON 16035\n",
      "CA 11279\n",
      "NV 13680\n",
      "AZ 15332\n",
      "TX 15781\n",
      "WA 15903\n",
      "CO 15913\n",
      "FL 15871\n",
      "UT 15902\n",
      "nan 15921\n",
      "NY 15978\n",
      "IL 16049\n",
      "OR 16138\n",
      "MO 16151\n",
      "NJ 16159\n",
      "OH 16195\n",
      "BC 16198\n",
      "ON 16223\n",
      "MI 16193\n",
      "WI 16215\n",
      "AB 16253\n",
      "TN 16253\n",
      "HI 16252\n",
      "PA 16239\n",
      "MN 16263\n",
      "NC 16229\n",
      "IN 16270\n",
      "GA 16251\n",
      "KS 16282\n",
      "MA 16273\n",
      "ID 16296\n",
      "NM 16315\n",
      "VA 16305\n",
      "OK 16326\n",
      "MD 16325\n",
      "CT 16321\n",
      "KY 16324\n",
      "MT 16332\n",
      "AR 16333\n",
      "QC 16336\n",
      "NE 16344\n",
      "IA 16330\n",
      "AL 16349\n",
      "WY 16351\n",
      "RI 16355\n",
      "AK 16355\n",
      "MB 16362\n",
      "SK 16360\n",
      "NSW 16366\n",
      "SC 16355\n",
      "NH 16360\n",
      "DE 16369\n",
      "Baja California 16376\n",
      "VT 16373\n",
      "MS 16375\n",
      "SD 16372\n",
      "DC 16377\n",
      "Email_Username 13834\n",
      "gmail.com 11978\n",
      "PET 13352\n",
      "yahoo.com 14231\n",
      "aol.com 15270\n",
      "hotmail.com 15542\n",
      "cox.net 16093\n",
      "sbcglobal.net 16164\n",
      "msn.com 16169\n",
      "comcast.net 16242\n",
      "live.com 16234\n",
      "att.net 16274\n",
      "Aux6_0.0 16217\n",
      "Aux6_1.0 15560\n",
      "Aux6_nan 15387\n",
      "ApprovalUserId_0.0 16359\n",
      "ApprovalUserId_20.0 16359\n",
      "ApprovalUserId_nan 16390\n",
      "LangId_0.0 16323\n",
      "LangId_1.0 16323\n",
      "LangId_nan 16390\n",
      "MemberStatus_FullMember 16336\n",
      "MemberStatus_NonMember 16323\n",
      "MemberStatus_nan 16377\n",
      "MemberStatus_nan.1 16390\n",
      "TermsAccepted_accepted 14551\n",
      "TermsAccepted_nan 14551\n",
      "TermsAccepted_nan.1 16390\n",
      "Days_to_Event 662\n",
      "Days_to_Event_Modify 664\n",
      "sum_response 8428\n"
     ]
    }
   ],
   "source": [
    "for a in train_X.columns:\n",
    "    print a,train_X[a].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Days_to_Event','Days_to_Event_Modify','TermsAccepted_accepted','Email_Username','AmountBilled','PET','Distance','CA', 'NV', 'AZ','TX','WA','CO','FL', 'UT', 'nan','NY','sum_response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_T = train_X[['0201', '0202','0203', '0204', '0205','0206','0207','0208','0209','0210','0211','0212', '0213', '0214', '0215', '0216', '0217', '0218', '0219', '0220','0221', '0222', '0223', '0224','0225', '0226', '0227','4301','4302','4303','4312','4313','4324','4329','4330', '403','aol.com','yahoo.com','hotmail.com','cox.net','MemberStatus_FullMember','AmountPaid', 'AmountDue','ATL', 'Company','Days_to_Event','Days_to_Event_Modify','TermsAccepted_accepted','Email_Username','AmountBilled','PET','Distance','CA', 'NV', 'AZ','TX','WA','CO','FL','UT','nan','NY','sum_response']]\n",
    "#76% roc lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(train_T) \n",
    "seed = 7\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.759860 (0.012818)\n",
      "LASSO: 0.633959 (0.019591)\n",
      "Ridge: 0.733781 (0.013736)\n",
      "LDA: 0.733777 (0.013709)\n",
      "NB: 0.676630 (0.014195)\n",
      "KNeighborsClassifier: 0.768854 (0.010047)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-5aa9dfce8166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s: %f (%f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\xgboost\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                               verbose_eval=verbose)\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "models.append(('LASSO', Lasso())) \n",
    "models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))#ewights = 'distance' \n",
    "models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "#models.append(('SVC', SVC(kernel = 'linear', random_state = seed)))\n",
    "#models.append(('LinearSVR', LinearSVR(random_state = seed)))\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "    \n",
    "    cv_results = model_selection.cross_val_score(model, train_T, train_Y, cv=kfold, scoring = scoring)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_P= test_X[['0201', '0202','0203', '0204', '0205','0206','0207','0208','0209','0210','0211','0212', '0213', '0214', '0215', '0216', '0217', '0218', '0219', '0220','0221', '0222', '0223', '0224','0225', '0226', '0227','4301','4302','4303','4312','4313','4324','4329','4330', '403','aol.com','yahoo.com','hotmail.com','cox.net','MemberStatus_FullMember','AmountPaid', 'AmountDue','ATL', 'Company','Days_to_Event','Days_to_Event_Modify','TermsAccepted_accepted','Email_Username','AmountBilled','PET','Distance','CA', 'NV', 'AZ','TX','WA','CO','sum_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  RandomForestClassifier(random_state = seed)\n",
    "model.fit(train_T, train_Y)\n",
    "#test_preds = model.predict(test_X)\n",
    "array = model.predict(train_T)\n",
    "probab = model.predict_proba(train_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960158633313\n",
      "0.99204066826\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(train_Y, array)\n",
    "print metrics.roc_auc_score(train_Y, probab[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1]\n",
      " [8201 8189]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(array, return_counts=True)  # this is predictions\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(train_Y, return_counts=True) #this is actual\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7875,  320],\n",
       "       [ 333, 7862]], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_Y, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of feature: 16\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(random_state = seed)\n",
    "rfe = RFECV(estimator,cv = kfold)\n",
    "fit = rfe.fit(train_T,train_Y)\n",
    "print(\"Num of feature: %d\") % fit.n_features_\n",
    "#print(\"Selected features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_65_important_features = [] \n",
    "for b in range(0,len(fit.ranking_)):\n",
    "    if fit.ranking_[b] == 1:\n",
    "        top_65_important_features.append(b)\n",
    "        print b,train_X.columns[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X = train_X.iloc[:,top_65_important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_65_important_features = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-2ef97b2fde34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s: %f (%f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "#models.append(('LASSO', Lasso())) \n",
    "#models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier())) \n",
    "models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "#models.append(('SVC', SVC(kernel = 'linear', random_state = seed)))\n",
    "#models.append(('LinearSVR', LinearSVR(random_state = seed)))\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, train_Y, cv=kfold, scoring= scoring)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame({'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z=[]\n",
    "Z=pd.concat([X,train_Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = Z.select_dtypes(include = ['int64', 'float64','uint8']).iloc[:, 1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(60, 60))\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr, mask=mask, vmin = -1, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LR', 'KNeighborsClassifier', 'RandomForestClassifier', 0.85369773310560304, 0.0074974399523090171)\n",
      "('LR', 'KNeighborsClassifier', 'ExtraTreesClassifier', 0.85493828459381971, 0.0087903236616036669)\n",
      "('LR', 'XGBClassifier', 'RandomForestClassifier', 0.85486887655878885, 0.0084441092122449091)\n",
      "('LR', 'XGBClassifier', 'ExtraTreesClassifier', 0.85615346320586616, 0.0087860251358491352)\n",
      "('LR', 'GradientBoostingClassifier', 'RandomForestClassifier', 0.85548179096871357, 0.0087556884215473311)\n",
      "('LR', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 0.85671676466978164, 0.0090803949059594762)\n",
      "('LR', 'AdaBoostClassifier', 'RandomForestClassifier', 0.85188208214529548, 0.0088626699608252077)\n",
      "('LR', 'RandomForestClassifier', 'ExtraTreesClassifier', 0.85688839965691055, 0.0093673845581198571)\n",
      "('LDA', 'XGBClassifier', 'ExtraTreesClassifier', 0.85002648382492585, 0.0097600352542832527)\n",
      "('LDA', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 0.85067654632557921, 0.0099652017836868688)\n",
      "('LDA', 'RandomForestClassifier', 'ExtraTreesClassifier', 0.85099909875708024, 0.010473968278613079)\n",
      "('KNeighborsClassifier', 'XGBClassifier', 'RandomForestClassifier', 0.85778940035757179, 0.0077747296865422304)\n",
      "('KNeighborsClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 0.85922477764836136, 0.0086201635223766924)\n",
      "('KNeighborsClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 0.85813013226815271, 0.0080148067711379514)\n",
      "('KNeighborsClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 0.85954813064705182, 0.0087746308721897773)\n",
      "('KNeighborsClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 0.85105187841114682, 0.010110147404129272)\n",
      "('XGBClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 0.8527855044722743, 0.0096591944054838889)\n",
      "('XGBClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 0.85465811304155237, 0.0096226611451066483)\n",
      "('XGBClassifier', 'AdaBoostClassifier', 'RandomForestClassifier', 0.85422688700698879, 0.009878735345783549)\n",
      "('XGBClassifier', 'AdaBoostClassifier', 'ExtraTreesClassifier', 0.85391765351827775, 0.0099406959111860826)\n",
      "('XGBClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 0.85767957009322582, 0.0099945499973182108)\n",
      "('GradientBoostingClassifier', 'AdaBoostClassifier', 'RandomForestClassifier', 0.85498793192400435, 0.010080002000850567)\n",
      "('GradientBoostingClassifier', 'AdaBoostClassifier', 'ExtraTreesClassifier', 0.8545833276431527, 0.010016738518716902)\n",
      "('GradientBoostingClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 0.8581001058454909, 0.010051865041365727)\n"
     ]
    }
   ],
   "source": [
    "for a in range(0, len(models)):\n",
    "    model1 = models[a]\n",
    "    for b in range(a+1, len(models)):\n",
    "        model2 = models[b]\n",
    "        for c in range(b+1, len(models)):\n",
    "            model3 = models[c]\n",
    "            estimators = []\n",
    "            estimators.append(model1)\n",
    "            estimators.append(model2)\n",
    "            estimators.append(model3)\n",
    "            ensemble = VotingClassifier(estimators, voting='soft')\n",
    "            results = model_selection.cross_val_score(ensemble, train_T, train_Y, cv=kfold, scoring= scoring)\n",
    "            if results.mean() > .85:\n",
    "                print(model1[0], model2[0], model3[0],results.mean(), results.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "estimators.append(('LR',LogisticRegression(random_state = seed)))\n",
    "estimators.append(('XGBClassifier',xgb.XGBClassifier()))\n",
    "estimators.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(train_T, train_Y)\n",
    "predict = ensemble.predict(test_P)\n",
    "probab = ensemble.predict_proba(test_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_val_score(ensemble, train_T, train_Y, cv=kfold, scoring= scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = ('LR', LogisticRegression(random_state = seed)'LR', 'XGBClassifier', 'RandomForestClassifier', 0.85486887655878885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_P = test_X[[ '0201', '0202','0203', '0204', '0205','0206','0207','0208','0209','0210','0211','0212', '0213', '0214', '0215', '0216', '0217', '0218', '0219', '0220','0221', '0222', '0223', '0224','0225', '0226', '0227','4301','4302','4303','4312','4313','4324','4329','4330', '403','aol.com','yahoo.com','hotmail.com','cox.net','MemberStatus_FullMember','AmountPaid', 'AmountDue','ATL', 'Company','Days_to_Event','Days_to_Event_Modify','TermsAccepted_accepted','Email_Username','AmountBilled','PET','Distance','CA', 'NV', 'AZ','TX','WA','CO','sum_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  LogisticRegression(random_state = seed)\n",
    "model.fit(train_T,train_Y)\n",
    "predict = model.predict(test_P)\n",
    "probab = model.predict_proba(test_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73374340949\n",
      "0.73901356817\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(test_Y, predict)\n",
    "print metrics.roc_auc_score(test_Y, probab[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1506, 1610],\n",
       "       [1070, 6056]], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_Y, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "e = 0\n",
    "for idx, val in enumerate(probab):\n",
    "    if val[0] > .80:\n",
    "        c += 1\n",
    "        if test_Y[idx] == 0:\n",
    "            print c, 0, idx, val[0]\n",
    "        else: \n",
    "            e += 1\n",
    "            print c, 0, idx, val[0], \"error\"\n",
    "            \n",
    "   \n",
    "    if val[1] > .80:\n",
    "        c += 1\n",
    "        if test_Y[idx] == 1:\n",
    "            print c, 1, idx, val[1]\n",
    "        else:\n",
    "            e += 1\n",
    "            print c, 1, idx, val[1], \"error\"\n",
    "print e\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "estimators.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "estimators.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(X, train_Y)\n",
    "predict = ensemble.predict(test_X[X.columns])\n",
    "probab = ensemble.predict_proba(test_X[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print metrics.accuracy_score(test_Y, predict)\n",
    "print metrics.roc_auc_score(test_Y, probab[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print metrics.confusion_matrix(test_Y, predict)\n",
    "#print metrics.classification_report(test_Y, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
