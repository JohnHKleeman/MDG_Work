{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.0.0\n",
      "numpy: 1.13.3\n",
      "matplotlib: 2.1.0\n",
      "pandas: 0.21.0\n",
      "sklearn: 0.19.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j_coo\\Anaconda2new\\envs\\trozziwork\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__)) # numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) # pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "#scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import xlrd\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = pd.read_excel('ATTENDEEISSA2017NumericalExcel.xlsx', header = None)\n",
    "#data_antendees = pd.read_excel('HW3Data.xlsx', sheetname = 'trainY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 345)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data_a.apply(pd.to_numeric, errors='ignore')    #changes dataframe dtypes to their lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data_a.iloc[0])):\n",
    "    if pd.isnull(data_a.iloc[0][i]):\n",
    "        data_a.iloc[0][i] = data_a.iloc[1][i]\n",
    "    else:\n",
    "        try:\n",
    "            if 'Response' not in data_a.iloc[1][i] and 'nan' not in data_a.iloc[1][i]:\n",
    "                data_a.iloc[0][i] = data_a.iloc[1][i] + ' ' + data_a.iloc[0][i]\n",
    "        except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = data_a.iloc[0] #grab the first row for the header\n",
    "data_a = data_a[1:] #take the data less the header row\n",
    "data_a.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a.drop(data_a.index[:1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 345)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = list(data_a)    # THIS DROPS ALL COLUMNS THAT HAVE THE SAME VALUE\n",
    "nunique = data_a.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "data_a = data_a.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data_a.apply(pd.to_numeric, errors='ignore')    #changes dataframe dtypes to their lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data_a.loc[: , ~data_a.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 133)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data_a.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 127)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorr = test.iloc[:,26:73]\n",
    "plt.figure(figsize=(150, 150))\n",
    "sns.heatmap(testcorr,vmin=-1, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorr = testcorr.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(150, 150))\n",
    "sns.heatmap(testcorr,vmin=-1, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(testcorr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(60, 60))\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(testcorr, mask=mask, vmin = -1, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(testcorr,vmin=-1, vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = data_a.select_dtypes(include = ['int64', 'float64']).iloc[:, 1:].corr()\n",
    "plt.figure(figsize=(150, 150))\n",
    "sns.heatmap(corr,vmin=-1, vmax=1, square=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = data_a[np.isfinite(data_a.iloc[:,118])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(465, 127)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_happy = []\n",
    "for a in range(0,len(data_a.iloc[:,118])):\n",
    "    if data_a.iloc[a,118] == 5 or data_a.iloc[a,118]==4:\n",
    "        sum_happy.append(3)\n",
    "    elif data_a.iloc[a,118] == 3:\n",
    "        sum_happy.append(2)\n",
    "    elif data_a.iloc[a,118] ==2 or data_a.iloc[a,118]==1:\n",
    "        sum_happy.append(1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a['sum_happy'] = sum_happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(465, 128)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_Y = data_a.iloc[:,118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_Y = data_Y.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_a.drop(data_a.columns[[118]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_X.select_dtypes(include = ['int64', 'float64']).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(465, 106)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_X.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "5      3.0\n",
       "6      2.0\n",
       "8      3.0\n",
       "10     2.0\n",
       "11     2.0\n",
       "12     3.0\n",
       "13     2.0\n",
       "14     1.0\n",
       "15     1.0\n",
       "16     1.0\n",
       "17     1.0\n",
       "18     1.0\n",
       "20     2.0\n",
       "21     2.0\n",
       "22     2.0\n",
       "24     2.0\n",
       "25     1.0\n",
       "26     1.0\n",
       "28     4.0\n",
       "29     1.0\n",
       "30     2.0\n",
       "31     2.0\n",
       "32     1.0\n",
       "35     1.0\n",
       "36     1.0\n",
       "37     2.0\n",
       "38     1.0\n",
       "      ... \n",
       "692    2.0\n",
       "693    2.0\n",
       "695    2.0\n",
       "696    1.0\n",
       "706    2.0\n",
       "708    3.0\n",
       "718    1.0\n",
       "720    1.0\n",
       "723    1.0\n",
       "724    2.0\n",
       "727    4.0\n",
       "728    1.0\n",
       "731    5.0\n",
       "732    4.0\n",
       "734    5.0\n",
       "736    2.0\n",
       "737    1.0\n",
       "739    1.0\n",
       "740    5.0\n",
       "741    5.0\n",
       "743    4.0\n",
       "745    5.0\n",
       "746    3.0\n",
       "747    5.0\n",
       "748    4.0\n",
       "749    5.0\n",
       "750    1.0\n",
       "753    2.0\n",
       "754    5.0\n",
       "755    2.0\n",
       "Name: Is your company planning to attend ISSA/INTERCLEAN North America 2018 in Dallas - October 29 – November 1, 2018?, Length: 465, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Y = data_Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_X\n",
    "y = data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_folds = 10\n",
    "num_instances = len(X) \n",
    "seed = 7\n",
    "scoring = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.iloc[:,105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(X.columns[105], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.647364 (0.052796)\n",
      "LASSO: -0.035860 (0.067703)\n",
      "Ridge: -0.183423 (0.300751)\n",
      "LDA: 0.640749 (0.058719)\n",
      "NB: 0.275162 (0.042810)\n",
      "CART: 0.535800 (0.085760)\n",
      "KNeighborsClassifier: 0.655920 (0.037900)\n",
      "GradientBoostingClassifier: 0.634366 (0.057400)\n",
      "AdaBoostClassifier: 0.602174 (0.061124)\n",
      "RandomForestClassifier: 0.668733 (0.062630)\n",
      "ExtraTreesClassifier: 0.655828 (0.071099)\n",
      "DecisionTreeClassifier: 0.524931 (0.084338)\n",
      "SVC: 0.677336 (0.063651)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LASSO', Lasso())) \n",
    "models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('CART', DecisionTreeClassifier())) \n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier())) \n",
    "#models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('SVC', SVC()))\n",
    "# evaluate each model in turn\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring= scoring)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "rfe = RFE(model,1 )\n",
    "fit = rfe.fit(X,y)\n",
    "print(\"Num of feature: %d\") % fit.n_features_\n",
    "print(\"Selected features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "the_list = []\n",
    "the_column = []\n",
    "fit = rfe.fit(X,y)\n",
    "rfe = RFE(model,1)\n",
    "    #print(\"Selected features: %s\") % fit.support_\n",
    "for a in range(1,8):\n",
    "    for b in range(0,len(fit.ranking_)):\n",
    "        if fit.ranking_[b] == a:\n",
    "            print a, b, X.columns[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "#models.append(('LASSO', Lasso())) \n",
    "#models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state = seed))) \n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier())) \n",
    "#models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "models.append(('SVC', SVC(probability = True, random_state = seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_ensemble(elist,single_score):\n",
    "    \n",
    "    for l in range(0, len(elist)):\n",
    "        model1=elist[l]\n",
    "        for j in range((l+1), len(elist)):\n",
    "            model2=elist[j]\n",
    "            for k in range((j+1), len(elist)):\n",
    "                model3=elist[k]\n",
    "                estimators=[]\n",
    "                estimators.append(model1)\n",
    "                estimators.append(model2)\n",
    "                estimators.append(model3)\n",
    "                #try:\n",
    "                    \n",
    "                ensemble = VotingClassifier(estimators, voting='soft')\n",
    "                cv_results = model_selection.cross_val_score(ensemble, X, y,scoring = None, cv=kfold) \n",
    "                if cv_results.mean() > single_score:\n",
    "                    print estimators[0][0], estimators[1][0], estimators[2][0]\n",
    "                    msg = \"%f (%f)\" % (cv_results.mean(), cv_results.std())\n",
    "                    print msg\n",
    "                \n",
    "                 \n",
    "                \n",
    "                #except:\n",
    "                    #msg = \" BREAK with: \" + estimators[0][0], estimators[1][0],estimators[2][0]\n",
    "                    #print msg\n",
    "                    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR KNeighborsClassifier SVC\n",
      "0.681545 (0.065487)\n"
     ]
    }
   ],
   "source": [
    "test_ensemble(models, 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655782 (0.063327)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "model1 = ExtraTreesClassifier(random_state = seed)\n",
    "estimators.append(('ExtraTreesClassifier', model1))\n",
    "model2 = KNeighborsClassifier()\n",
    "estimators.append(('KNeighborsClassifier', model2))\n",
    "model3 = GradientBoostingClassifier(random_state = seed)\n",
    "estimators.append(('GradientBoostingClassifier', model3))\n",
    "\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(ensemble, X, y, cv=kfold, scoring= scoring) \n",
    "msg = \"%f (%f)\" % (cv_results.mean(), cv_results.std())\n",
    "print msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664292 (0.070169)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "estimators = []\n",
    "model1 = ExtraTreesClassifier()\n",
    "estimators.append(('ExtraTreesClassifier', model1))\n",
    "model2 = KNeighborsClassifier()\n",
    "estimators.append(('KNeighborsClassifier', model2))\n",
    "model3 = GradientBoostingClassifier()\n",
    "estimators.append(('GradientBoostingClassifier', model3))\n",
    "\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "cv_results = model_selection.cross_val_score(ensemble, X, y,scoring = scoring, cv=kfold) \n",
    "msg = \"%f (%f)\" % (cv_results.mean(), cv_results.std())\n",
    "print msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=32,\n",
       "              presort='auto', random_state=7, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier(n_estimators= 32, learning_rate= 0.1, random_state= 7, max_depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [10,20,30], 'learning_rate': [.1,.01,.001], 'random_state': [7], 'max_depth': [2,3,5,7]}\n",
    "local_cv(GradientBoostingClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cv(model, params):                             #KFOLD WITH GRID SEARCH\n",
    "    param_grid = params\n",
    "    kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X, y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    for params, mean_score, scores in grid_result.grid_scores_:\n",
    "        print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finding and recommendations,  The question you want to predict for, ask first in your survey, for optimal data collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
